{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b37e1e5-1ac8-4d84-b16f-517faa60985c",
   "metadata": {},
   "source": [
    " ## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caf8261-08fd-4f90-8df6-7eacff36dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% [code]\n",
    "\n",
    "# Includes\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "import pytensor.tensor as at\n",
    "\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True,precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c728db-78ce-412f-9d60-4ee21c8d9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% [code]\n",
    "\n",
    "# Load data\n",
    "\n",
    "from load_data import load_data_for_experiments, load_data_for_experiment\n",
    "\n",
    "experiment_version = \"V1.0_pilot\"\n",
    "data = load_data_for_experiment(experiment_version)\n",
    "\n",
    "#experiment_versions = [\"V0.3_pilot\", \"V1.0_pilot\", \"V1.1_pilot\"]\n",
    "#data = load_data_for_experiments(experiment_versions)\n",
    "\n",
    "counts = data['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9eb3b8-b67b-4447-bd01-7306faf48768",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% [code]\n",
    "\n",
    "# Prepare data\n",
    "\n",
    "# SYNTHETIC DATA for model recoverability\n",
    "synthetic_hybrid_counts = np.tile(np.array([10, 5, 5, 1, 1, 4]), (30, 1))\n",
    "\n",
    "synthetic_mixture_counts = np.vstack([\n",
    "    np.tile(np.array([20, 1, 1, 1, 1, 4]), (15, 1)),\n",
    "    np.tile(np.array([2, 10, 10, 1, 1, 4]), (15, 1))\n",
    "])\n",
    "\n",
    "synthetic_mixture_3_counts = np.vstack([\n",
    "    np.tile(np.array([20, 1, 1, 1, 1, 4]), (10, 1)),\n",
    "    np.tile(np.array([2, 10, 10, 1, 1, 4]), (10, 1)),\n",
    "    np.tile(np.array([1, 1, 1, 1, 20, 4]), (10, 1))\n",
    "])\n",
    "\n",
    "synthetic_hybrid_2_counts = np.tile(np.array([10, 5, 5, 1, 10, 4]), (30, 1))\n",
    "\n",
    "synthetic_mixture_4_counts = np.vstack([\n",
    "    np.tile(np.array([10, 5, 5, 1, 1, 4]), (15, 1)),\n",
    "    np.tile(np.array([1, 1, 1, 1, 20, 4]), (15, 1))\n",
    "])\n",
    "#counts = synthetic_mixture_3_counts\n",
    "\n",
    "S, K = counts.shape\n",
    "N = counts.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8cb03-9242-4188-aea4-5deeb0a7b2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "/home/momchil.tomov/miniconda3/envs/analysis/lib/python3.12/site-packages/pytensor/link/c/cmodule.py:2986: UserWarning: PyTensor could not link to a BLAS installation. Operations that might benefit from BLAS will be severely degraded.\n",
      "This usually happens when PyTensor is installed via pip. We recommend it be installed via conda/mamba/pixi instead.\n",
      "Alternatively, you can use an experimental backend such as Numba or JAX that perform their own BLAS optimizations, by setting `pytensor.config.mode == 'NUMBA'` or passing `mode='NUMBA'` when compiling a PyTensor function.\n",
      "For more options and details see https://pytensor.readthedocs.io/en/latest/troubleshooting.html#how-do-i-configure-test-my-blas-library\n",
      "  warnings.warn(\n",
      "Multiprocess sampling (8 chains in 4 jobs)\n",
      "NUTS: [u_e, u_n, u_m, c]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294f96fcf94d4f7ba5f67058fa29e4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 8 chains for 10_000 tune and 10_000 draw iterations (80_000 + 80_000 draws total) took 130 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid model convergence diagnostics:\n",
      "      mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\n",
      "u_e  0.084  0.021   0.045    0.111      0.000    0.000   21766.0   26452.0   \n",
      "u_n  0.240  0.084   0.083    0.397      0.001    0.000   26249.0   23304.0   \n",
      "u_m  0.262  0.083   0.100    0.415      0.001    0.000   25447.0   23355.0   \n",
      "c    4.135  0.660   2.957    5.390      0.003    0.003   40713.0   45295.0   \n",
      "\n",
      "     r_hat  \n",
      "u_e    1.0  \n",
      "u_n    1.0  \n",
      "u_m    1.0  \n",
      "c      1.0  \n"
     ]
    }
   ],
   "source": [
    "#%% [code]\n",
    "\n",
    "# Hybrid model: GPI zero + Policy reuse cued\n",
    "\n",
    "with pm.Model() as hybrid_model:\n",
    "    # positive raw weights for the tied pattern [n, m, m, e, e, 4e]\n",
    "    u_e = pm.Uniform(\"u_e\", lower=0.0, upper=1/9)\n",
    "    u_n = pm.Uniform(\"u_n\", lower=u_e, upper=1.0)\n",
    "    u_m = pm.Uniform(\"u_m\", lower=u_e, upper=1.0)\n",
    "\n",
    "    # total concentration (how similar subjects are)\n",
    "    c = pm.LogNormal(\"c\", mu=0.0, sigma=1.5)\n",
    "\n",
    "    # construct tied base proportions\n",
    "    theta_raw = at.stack([u_n, u_m, u_m, u_e, u_e, 4*u_e])\n",
    "    theta = theta_raw / theta_raw.sum()\n",
    "\n",
    "    # Dirichlet parameters\n",
    "    alpha = c * theta\n",
    "\n",
    "    # vectorized Dirichlet–Multinomial over subjects\n",
    "    pm.DirichletMultinomial(\"x\", a=alpha, n=N, shape=(S, K), observed=counts)\n",
    "\n",
    "    hybrid_trace = pm.sample(10000, tune=10000, target_accept=0.95, chains=8, idata_kwargs={\"log_likelihood\": True}, return_inferencedata=True)\n",
    "    # Check convergence\n",
    "    print(\"Hybrid model convergence diagnostics:\")\n",
    "    print(az.summary(hybrid_trace))\n",
    "    # predictive accuracy (subject-level pointwise log-lik is handled internally)\n",
    "    loo_hybrid = az.loo(hybrid_trace)     # or az.waic(idata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d3614-bce0-432d-9954-ce0ac2cd9b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (8 chains in 4 jobs)\n",
      "NUTS: [w, u_e1, u_e2, u_n, u_m, c1, c2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ef553ceda843409e050ee5637be0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 8 chains for 10_000 tune and 10_000 draw iterations (80_000 + 80_000 draws total) took 327 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixture model convergence diagnostics:\n",
      "        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\n",
      "w[0]   0.570  0.115   0.354    0.784      0.001    0.001   53889.0   36131.0   \n",
      "w[1]   0.430  0.115   0.216    0.646      0.001    0.001   53889.0   36131.0   \n",
      "u_e1   0.075  0.026   0.028    0.111      0.000    0.000   36006.0   36456.0   \n",
      "u_e2   0.066  0.026   0.024    0.111      0.000    0.000   36294.0   36603.0   \n",
      "u_n    0.250  0.119   0.039    0.454      0.001    0.001   36156.0   32610.0   \n",
      "u_m    0.619  0.235   0.219    1.000      0.001    0.001   32821.0   34261.0   \n",
      "c1     5.221  1.227   3.071    7.533      0.005    0.006   65943.0   49600.0   \n",
      "c2    14.190  6.475   4.715   25.381      0.030    0.095   52476.0   49734.0   \n",
      "\n",
      "      r_hat  \n",
      "w[0]    1.0  \n",
      "w[1]    1.0  \n",
      "u_e1    1.0  \n",
      "u_e2    1.0  \n",
      "u_n     1.0  \n",
      "u_m     1.0  \n",
      "c1      1.0  \n",
      "c2      1.0  \n"
     ]
    }
   ],
   "source": [
    "#%% [code]\n",
    "\n",
    "# Mixture:\n",
    "#   1) GPI zero\n",
    "#   2) Policy reuse cued\n",
    "\n",
    "with pm.Model() as mixture_model:\n",
    "    # mixture weight\n",
    "    w = pm.Dirichlet('w', a=np.ones(2))\n",
    "    # raw weights (positive)\n",
    "    u_e1  = pm.Uniform('u_e1', lower=0.0, upper=1/9)\n",
    "    u_e2  = pm.Uniform('u_e2', lower=0.0, upper=1/9)\n",
    "    u_n   = pm.Uniform('u_n', lower=u_e1, upper=1.0)\n",
    "    u_m   = pm.Uniform('u_m', lower=u_e2, upper=1.0)\n",
    "\n",
    "    # concentration\n",
    "    c1 = pm.LogNormal('c1', 0.0, 1.5)\n",
    "    c2 = pm.LogNormal('c2', 0.0, 1.5)\n",
    "\n",
    "    # component base measures\n",
    "    theta1_raw = pm.math.stack([u_n, u_e1, u_e1, u_e1, u_e1, 4*u_e1])\n",
    "    theta2_raw = pm.math.stack([u_e2, u_m,  u_m,  u_e2, u_e2, 4*u_e2])\n",
    "    theta1 = theta1_raw / pm.math.sum(theta1_raw)\n",
    "    theta2 = theta2_raw / pm.math.sum(theta2_raw)\n",
    "\n",
    "    alpha1 = c1 * theta1\n",
    "    alpha2 = c2 * theta2\n",
    "\n",
    "    # subject-level mixture likelihood (marginal over z)\n",
    "    # PyMC has DirichletMultinomial: pm.DirichletMultinomial\n",
    "    like1 = pm.DirichletMultinomial.dist(a=alpha1, n=counts.sum(axis=1))\n",
    "    like2 = pm.DirichletMultinomial.dist(a=alpha2, n=counts.sum(axis=1))\n",
    "\n",
    "    # mixture across subjects\n",
    "    pm.Mixture('x', w, comp_dists=[like1, like2], observed=counts)\n",
    "\n",
    "    mixture_trace = pm.sample(10000, tune=10000, target_accept=0.95, chains=8, idata_kwargs={\"log_likelihood\": True}, return_inferencedata=True)\n",
    "    # Check convergence\n",
    "    print(\"Mixture model convergence diagnostics:\")\n",
    "    print(az.summary(mixture_trace))\n",
    "    loo_mixture = az.loo(mixture_trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053180f4-a6d4-4948-b3ce-14d741525bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (8 chains in 4 jobs)\n",
      "NUTS: [w, u_e1, u_e2, u_e3, u_n, u_m, u_o, c1, c2, c3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0507c37980cd40d2ab9a192f506fd366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 8 chains for 10_000 tune and 10_000 draw iterations (80_000 + 80_000 draws total) took 514 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixture model 3 convergence diagnostics:\n",
      "        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\n",
      "w[0]   0.300  0.124   0.085    0.543      0.001    0.001   19100.0   15269.0   \n",
      "w[1]   0.405  0.098   0.223    0.589      0.000    0.000   74913.0   58089.0   \n",
      "w[2]   0.295  0.126   0.034    0.514      0.001    0.001   16898.0    9704.0   \n",
      "u_e1   0.072  0.026   0.026    0.111      0.000    0.000   47252.0   40820.0   \n",
      "u_e2   0.066  0.025   0.023    0.111      0.000    0.000   38571.0   35526.0   \n",
      "u_e3   0.074  0.026   0.026    0.111      0.000    0.000   48335.0   44590.0   \n",
      "u_n    0.491  0.236   0.093    0.933      0.001    0.001   24107.0   35652.0   \n",
      "u_m    0.640  0.232   0.236    1.000      0.001    0.001   38862.0   40833.0   \n",
      "u_o    0.267  0.156   0.017    0.529      0.001    0.002   24776.0   13423.0   \n",
      "c1     4.950  2.056   1.527    8.746      0.009    0.026   46160.0   36850.0   \n",
      "c2    15.338  6.221   5.784   26.325      0.026    0.046   69079.0   48221.0   \n",
      "c3    10.110  5.523   0.046   18.286      0.037    0.171   16207.0    5888.0   \n",
      "\n",
      "      r_hat  \n",
      "w[0]    1.0  \n",
      "w[1]    1.0  \n",
      "w[2]    1.0  \n",
      "u_e1    1.0  \n",
      "u_e2    1.0  \n",
      "u_e3    1.0  \n",
      "u_n     1.0  \n",
      "u_m     1.0  \n",
      "u_o     1.0  \n",
      "c1      1.0  \n",
      "c2      1.0  \n",
      "c3      1.0  \n"
     ]
    }
   ],
   "source": [
    "#%% [code]\n",
    "\n",
    "# Mixture:\n",
    "#   1) GPI zero\n",
    "#   2) Policy reuse cued\n",
    "#   3) Model-based / GPI\n",
    "\n",
    "with pm.Model() as mixture_model_3:\n",
    "    # mixture weight\n",
    "    w = pm.Dirichlet('w', a=np.ones(3))\n",
    "    \n",
    "    # raw weights (positive)\n",
    "    u_e1  = pm.Uniform('u_e1', lower=0.0, upper=1/9)\n",
    "    u_e2  = pm.Uniform('u_e2', lower=0.0, upper=1/9)\n",
    "    u_e3  = pm.Uniform('u_e3', lower=0.0, upper=1/9)\n",
    "    u_n   = pm.Uniform('u_n', lower=u_e1, upper=1.0)\n",
    "    u_m   = pm.Uniform('u_m', lower=u_e2, upper=1.0)\n",
    "    u_o   = pm.Uniform('u_o', lower=u_e3, upper=1.0)\n",
    "\n",
    "    # concentration\n",
    "    c1 = pm.LogNormal('c1', 0.0, 1.5)\n",
    "    c2 = pm.LogNormal('c2', 0.0, 1.5)\n",
    "    c3 = pm.LogNormal('c3', 0.0, 1.5)\n",
    "\n",
    "    # component base measures\n",
    "    theta1_raw = pm.math.stack([u_n, u_e1, u_e1, u_e1, u_e1, 4*u_e1])\n",
    "    theta2_raw = pm.math.stack([u_e2, u_m,  u_m,  u_e2, u_e2, 4*u_e2])\n",
    "    theta3_raw = pm.math.stack([u_e3, u_e3,  u_e3,  u_e3, u_o, 4*u_e3])\n",
    "    theta1 = theta1_raw / pm.math.sum(theta1_raw)\n",
    "    theta2 = theta2_raw / pm.math.sum(theta2_raw)\n",
    "    theta3 = theta3_raw / pm.math.sum(theta3_raw)\n",
    "    \n",
    "    alpha1 = c1 * theta1\n",
    "    alpha2 = c2 * theta2\n",
    "    alpha3 = c3 * theta3\n",
    "\n",
    "    # subject-level mixture likelihood (marginal over z)\n",
    "    # PyMC has DirichletMultinomial: pm.DirichletMultinomial\n",
    "    like1 = pm.DirichletMultinomial.dist(a=alpha1, n=counts.sum(axis=1))\n",
    "    like2 = pm.DirichletMultinomial.dist(a=alpha2, n=counts.sum(axis=1))\n",
    "    like3 = pm.DirichletMultinomial.dist(a=alpha3, n=counts.sum(axis=1))\n",
    "\n",
    "    # mixture across subjects\n",
    "    pm.Mixture('x', w, comp_dists=[like1, like2, like3], observed=counts)\n",
    "\n",
    "    mixture_trace_3 = pm.sample(10000, tune=10000, target_accept=0.95, chains=8, idata_kwargs={\"log_likelihood\": True}, return_inferencedata=True)\n",
    "    # Check convergence\n",
    "    print(\"Mixture model 3 convergence diagnostics:\")\n",
    "    print(az.summary(mixture_trace_3))\n",
    "    loo_mixture_3 = az.loo(mixture_trace_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f100198d-9369-427d-a36b-a73d3724b3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (8 chains in 4 jobs)\n",
      "NUTS: [u_e, u_n, u_m, u_o, c]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a167db36f747d3ab0edaad8456648d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 8 chains for 10_000 tune and 10_000 draw iterations (80_000 + 80_000 draws total) took 100 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid model 2 convergence diagnostics:\n",
      "      mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\n",
      "u_e  0.090  0.018   0.057    0.111      0.000    0.000   24281.0   31432.0   \n",
      "u_n  0.363  0.119   0.149    0.592      0.001    0.001   27472.0   29556.0   \n",
      "u_m  0.396  0.118   0.176    0.619      0.001    0.001   24969.0   28277.0   \n",
      "u_o  0.318  0.106   0.130    0.523      0.001    0.000   27589.0   28140.0   \n",
      "c    4.175  0.679   2.948    5.453      0.003    0.003   48446.0   50787.0   \n",
      "\n",
      "     r_hat  \n",
      "u_e    1.0  \n",
      "u_n    1.0  \n",
      "u_m    1.0  \n",
      "u_o    1.0  \n",
      "c      1.0  \n"
     ]
    }
   ],
   "source": [
    "#%% [code]\n",
    "\n",
    "# Hybrid model 2: GPI zero + Policy reuse cued + MB/GPI\n",
    "\n",
    "with pm.Model() as hybrid_model_2:\n",
    "    # positive raw weights for the tied pattern [n, m, m, e, o, 4e]\n",
    "    u_e = pm.Uniform(\"u_e\", lower=0.0, upper=1/9)\n",
    "    u_n = pm.Uniform(\"u_n\", lower=u_e, upper=1.0)\n",
    "    u_m = pm.Uniform(\"u_m\", lower=u_e, upper=1.0)\n",
    "    u_o = pm.Uniform(\"u_o\", lower=u_e, upper=1.0)\n",
    "\n",
    "    # total concentration (how similar subjects are)\n",
    "    c = pm.LogNormal(\"c\", mu=0.0, sigma=1.5)\n",
    "\n",
    "    # construct tied base proportions\n",
    "    theta_raw = at.stack([u_n, u_m, u_m, u_e, u_o, 4*u_e])\n",
    "    theta = theta_raw / theta_raw.sum()\n",
    "\n",
    "    # Dirichlet parameters\n",
    "    alpha = c * theta\n",
    "\n",
    "    # vectorized Dirichlet–Multinomial over subjects\n",
    "    pm.DirichletMultinomial(\"x\", a=alpha, n=N, shape=(S, K), observed=counts)\n",
    "\n",
    "    hybrid_trace_2 = pm.sample(10000, tune=10000, target_accept=0.95, chains=8, idata_kwargs={\"log_likelihood\": True}, return_inferencedata=True)\n",
    "    # Check convergence\n",
    "    print(\"Hybrid model 2 convergence diagnostics:\")\n",
    "    print(az.summary(hybrid_trace_2))\n",
    "    # predictive accuracy (subject-level pointwise log-lik is handled internally)\n",
    "    loo_hybrid_2 = az.loo(hybrid_trace_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821cf41e-4af6-4421-8f94-8cb83612b549",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (8 chains in 4 jobs)\n",
      "NUTS: [w, u_e1, u_e2, u_n, u_m, u_o, c1, c2]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6f34fb747e4a819d81c840f534ab30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 8 chains for 10_000 tune and 10_000 draw iterations (80_000 + 80_000 draws total) took 305 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixture model 4 convergence diagnostics:\n",
      "        mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\n",
      "w[0]   0.445  0.126   0.216    0.668      0.001    0.001   27525.0   12929.0   \n",
      "w[1]   0.555  0.126   0.332    0.784      0.001    0.001   27525.0   12929.0   \n",
      "u_e1   0.071  0.023   0.034    0.111      0.000    0.000   34610.0   32053.0   \n",
      "u_e2   0.075  0.026   0.028    0.111      0.000    0.000   45080.0   41325.0   \n",
      "u_n    0.180  0.082   0.043    0.333      0.000    0.000   40541.0   42295.0   \n",
      "u_m    0.712  0.203   0.345    1.000      0.001    0.001   31173.0   28226.0   \n",
      "u_o    0.184  0.093   0.030    0.334      0.001    0.002   36663.0   28278.0   \n",
      "c1    14.132  7.053   3.906   26.232      0.034    0.073   32448.0   16663.0   \n",
      "c2     4.361  1.127   2.433    6.544      0.007    0.010   32753.0   14913.0   \n",
      "\n",
      "      r_hat  \n",
      "w[0]    1.0  \n",
      "w[1]    1.0  \n",
      "u_e1    1.0  \n",
      "u_e2    1.0  \n",
      "u_n     1.0  \n",
      "u_m     1.0  \n",
      "u_o     1.0  \n",
      "c1      1.0  \n",
      "c2      1.0  \n"
     ]
    }
   ],
   "source": [
    "#%% [code]\n",
    "\n",
    "# Mixture 4:\n",
    "#   1) GPI zero + Policy reuse cued\n",
    "#   2) MB/GPI\n",
    "\n",
    "with pm.Model() as mixture_model_4:\n",
    "    # mixture weight\n",
    "    w = pm.Dirichlet('w', a=np.ones(2))\n",
    "    \n",
    "    # raw weights (positive)\n",
    "    u_e1  = pm.Uniform('u_e1', lower=0.0, upper=1/9)\n",
    "    u_e2  = pm.Uniform('u_e2', lower=0.0, upper=1/9)\n",
    "    u_n   = pm.Uniform('u_n', lower=u_e1, upper=1.0)\n",
    "    u_m   = pm.Uniform('u_m', lower=u_e1, upper=1.0)\n",
    "    u_o   = pm.Uniform('u_o', lower=u_e2, upper=1.0)\n",
    "\n",
    "    # concentration\n",
    "    c1 = pm.LogNormal('c1', 0.0, 1.5)\n",
    "    c2 = pm.LogNormal('c2', 0.0, 1.5)\n",
    "\n",
    "    # component base measures\n",
    "    # Component 1: GPI zero + Policy reuse cued [n, m, m, e, e, 4e]\n",
    "    theta1_raw = pm.math.stack([u_n, u_m, u_m, u_e1, u_e1, 4*u_e1])\n",
    "    # Component 2: MB/GPI [e, e, e, e, o, 4e]\n",
    "    theta2_raw = pm.math.stack([u_e2, u_e2, u_e2, u_e2, u_o, 4*u_e2])\n",
    "    theta1 = theta1_raw / pm.math.sum(theta1_raw)\n",
    "    theta2 = theta2_raw / pm.math.sum(theta2_raw)\n",
    "    \n",
    "    alpha1 = c1 * theta1\n",
    "    alpha2 = c2 * theta2\n",
    "\n",
    "    # subject-level mixture likelihood (marginal over z)\n",
    "    # PyMC has DirichletMultinomial: pm.DirichletMultinomial\n",
    "    like1 = pm.DirichletMultinomial.dist(a=alpha1, n=counts.sum(axis=1))\n",
    "    like2 = pm.DirichletMultinomial.dist(a=alpha2, n=counts.sum(axis=1))\n",
    "\n",
    "    # mixture across subjects\n",
    "    pm.Mixture('x', w, comp_dists=[like1, like2], observed=counts)\n",
    "\n",
    "    mixture_trace_4 = pm.sample(10000, tune=10000, target_accept=0.95, chains=8, idata_kwargs={\"log_likelihood\": True}, return_inferencedata=True)\n",
    "    # Check convergence\n",
    "    print(\"Mixture model 4 convergence diagnostics:\")\n",
    "    print(az.summary(mixture_trace_4))\n",
    "    loo_mixture_4 = az.loo(mixture_trace_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82300977-50ec-4cac-b6d8-1f963a246443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CONVERGENCE DIAGNOSTICS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "HYBRID MODEL:\n",
      "--------------------------------------------------------------------------------\n",
      "Max R-hat: 1.0000 ✓\n",
      "Min ESS (bulk): 21766 ✓\n",
      "\n",
      "MIXTURE MODEL:\n",
      "--------------------------------------------------------------------------------\n",
      "Max R-hat: 1.0000 ✓\n",
      "Min ESS (bulk): 32821 ✓\n",
      "\n",
      "MIXTURE_3 MODEL:\n",
      "--------------------------------------------------------------------------------\n",
      "Max R-hat: 1.0000 ✓\n",
      "Min ESS (bulk): 16207 ✓\n",
      "\n",
      "HYBRID_2 MODEL:\n",
      "--------------------------------------------------------------------------------\n",
      "Max R-hat: 1.0000 ✓\n",
      "Min ESS (bulk): 24281 ✓\n",
      "\n",
      "MIXTURE_4 MODEL:\n",
      "--------------------------------------------------------------------------------\n",
      "Max R-hat: 1.0000 ✓\n",
      "Min ESS (bulk): 27525 ✓\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%% [code]\n",
    "\n",
    "# Comprehensive convergence diagnostics\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONVERGENCE DIAGNOSTICS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "traces = {\n",
    "    \"hybrid\": hybrid_trace,\n",
    "    \"mixture\": mixture_trace,\n",
    "    \"mixture_3\": mixture_trace_3,\n",
    "    \"hybrid_2\": hybrid_trace_2,\n",
    "    \"mixture_4\": mixture_trace_4\n",
    "}\n",
    "\n",
    "for name, trace in traces.items():\n",
    "    print(f\"\\n{name.upper()} MODEL:\")\n",
    "    print(\"-\" * 80)\n",
    "    # Get summary which includes R-hat and ESS\n",
    "    summary = az.summary(trace)\n",
    "    \n",
    "    # Extract max R-hat and min ESS from summary\n",
    "    if 'r_hat' in summary.columns:\n",
    "        max_rhat = float(summary['r_hat'].max())\n",
    "        print(f\"Max R-hat: {max_rhat:.4f} {'✓' if max_rhat < 1.01 else '✗ WARNING: R-hat > 1.01'}\")\n",
    "    else:\n",
    "        # Fallback: compute directly\n",
    "        rhat = az.rhat(trace)\n",
    "        max_rhat = float(rhat.max().to_numpy())\n",
    "        print(f\"Max R-hat: {max_rhat:.4f} {'✓' if max_rhat < 1.01 else '✗ WARNING: R-hat > 1.01'}\")\n",
    "    \n",
    "    if 'ess_bulk' in summary.columns:\n",
    "        min_ess = float(summary['ess_bulk'].min())\n",
    "        print(f\"Min ESS (bulk): {min_ess:.0f} {'✓' if min_ess > 400 else '✗ WARNING: ESS < 400'}\")\n",
    "    elif 'ess_mean' in summary.columns:\n",
    "        min_ess = float(summary['ess_mean'].min())\n",
    "        print(f\"Min ESS (mean): {min_ess:.0f} {'✓' if min_ess > 400 else '✗ WARNING: ESS < 400'}\")\n",
    "    else:\n",
    "        # Fallback: compute directly\n",
    "        ess = az.ess(trace)\n",
    "        min_ess = float(ess.min().to_numpy())\n",
    "        print(f\"Min ESS: {min_ess:.0f} {'✓' if min_ess > 400 else '✗ WARNING: ESS < 400'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8966a1-aca0-4451-999c-187352ee45fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>elpd_loo</th>\n",
       "      <th>p_loo</th>\n",
       "      <th>elpd_diff</th>\n",
       "      <th>weight</th>\n",
       "      <th>se</th>\n",
       "      <th>dse</th>\n",
       "      <th>warning</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mixture_3</th>\n",
       "      <td>0</td>\n",
       "      <td>-301.518286</td>\n",
       "      <td>7.781459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.467214e-01</td>\n",
       "      <td>8.234380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture</th>\n",
       "      <td>1</td>\n",
       "      <td>-304.547087</td>\n",
       "      <td>6.486995</td>\n",
       "      <td>3.028801</td>\n",
       "      <td>2.191483e-01</td>\n",
       "      <td>9.482639</td>\n",
       "      <td>3.329168</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid_2</th>\n",
       "      <td>2</td>\n",
       "      <td>-306.716681</td>\n",
       "      <td>5.291372</td>\n",
       "      <td>5.198395</td>\n",
       "      <td>3.341303e-01</td>\n",
       "      <td>5.122518</td>\n",
       "      <td>5.776640</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixture_4</th>\n",
       "      <td>3</td>\n",
       "      <td>-308.603360</td>\n",
       "      <td>7.837388</td>\n",
       "      <td>7.085074</td>\n",
       "      <td>2.018339e-14</td>\n",
       "      <td>7.267170</td>\n",
       "      <td>4.132043</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hybrid</th>\n",
       "      <td>4</td>\n",
       "      <td>-313.903813</td>\n",
       "      <td>4.542803</td>\n",
       "      <td>12.385527</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.984115</td>\n",
       "      <td>5.471624</td>\n",
       "      <td>False</td>\n",
       "      <td>log</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           rank    elpd_loo     p_loo  elpd_diff        weight        se  \\\n",
       "mixture_3     0 -301.518286  7.781459   0.000000  4.467214e-01  8.234380   \n",
       "mixture       1 -304.547087  6.486995   3.028801  2.191483e-01  9.482639   \n",
       "hybrid_2      2 -306.716681  5.291372   5.198395  3.341303e-01  5.122518   \n",
       "mixture_4     3 -308.603360  7.837388   7.085074  2.018339e-14  7.267170   \n",
       "hybrid        4 -313.903813  4.542803  12.385527  0.000000e+00  6.984115   \n",
       "\n",
       "                dse  warning scale  \n",
       "mixture_3  0.000000    False   log  \n",
       "mixture    3.329168    False   log  \n",
       "hybrid_2   5.776640    False   log  \n",
       "mixture_4  4.132043    False   log  \n",
       "hybrid     5.471624    False   log  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% [code]\n",
    "\n",
    "# Compare models\n",
    "\n",
    "az.compare({\n",
    "    \"hybrid\": hybrid_trace,\n",
    "    \"mixture\": mixture_trace,\n",
    "    \"mixture_3\": mixture_trace_3,\n",
    "    \"hybrid_2\": hybrid_trace_2,\n",
    "    \"mixture_4\": mixture_trace_4\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
